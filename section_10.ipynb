{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 10: Install \"Kubernetes the Hard Way\"\n",
    "\n",
    "\n",
    "## 162. Section Introduction\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296180#overview\n",
    "\n",
    "Hello and welcome to this section.\n",
    "\n",
    "My name is Mumshad Mannambeth and we are going through the Certified Kubernetes Administrators Course.\n",
    "\n",
    "In this section\n",
    "\n",
    "we look at Installation, Configuration and Validation of a Kubernetes cluster.\n",
    "\n",
    "A lot of concepts that we went through, throughout this course, comes together in this section.\n",
    "\n",
    "We start by looking at the various aspects involved in designing a kubernetes cluster,\n",
    "\n",
    "We design our own small solution that we can deploy on a laptop or a local machine.\n",
    "\n",
    "We understand how a High Availability cluster works, how an ETCD cluster works and the best practices\n",
    "\n",
    "in deploying an HA cluster.\n",
    "\n",
    "We then go through an end to an installation process where we install and configure the designed solution\n",
    "\n",
    "on a local system using VirtualBox and Vagrant.\n",
    "\n",
    "This was again based on what you said about your preferred virtualization technology for labs.\n",
    "\n",
    "We use a modified version of Kelsey Hightowers Kubernetes the hard way to install it on a local system.\n",
    "\n",
    "We see two ways of bootstrapping a worker node. One the usual way and the other using the TLS Bootstrap\n",
    "\n",
    "approach.\n",
    "\n",
    "Once installed we run an end-to-end test using the kubernetes test infrastructure to validate our cluster.\n",
    "\n",
    "Well let's get started.\n",
    "\n",
    "\n",
    "\n",
    "## 163. Download Presentation Deck\n",
    "\n",
    "- Kubernetes -CKA- 0900 - Install-v1.4.pdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 164. Design a Kubernetes Cluster\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296182#overview\n",
    "\n",
    "Hello and welcome to this lecture. In this lecture\n",
    "\n",
    "we will discuss about designing a kubernetes cluster. Before you head into designing a cluster.\n",
    "\n",
    "I must ask the following questions.\n",
    "\n",
    "What is the purpose of this cluster?\n",
    "\n",
    "Is it for learning or development or testing purpose or for hosting production grade applications.\n",
    "\n",
    "What is the cloud adoption at your organization?\n",
    "\n",
    "Do you prefer your platform to be managed by a cloud provider or a self hosted?\n",
    "\n",
    "What kind of workloads are you going to run on this cluster?\n",
    "\n",
    "How many applications are to be hosted on the Cluster?\n",
    "\n",
    "Few or many?\n",
    "\n",
    "What kind of applications are going to be hosted on the Cluster? Web applications or big data or analytics?\n",
    "\n",
    "Depending on the kind of application the resource requirements may vary.\n",
    "\n",
    "What type of network traffic are these applications expecting?\n",
    "\n",
    "Continuous heavy traffic or burst?\n",
    "\n",
    "Well let's try and break down some of these.\n",
    "\n",
    "If you want to deploy a cluster for learning purposes then a solution based on minikube or a single\n",
    "\n",
    "node cluster deployed using kubeadm on local VMs or cloud providers like GCP or AWS should do.\n",
    "\n",
    "We have deployed such a cluster in the beginners course. To deploy a cluster for development and testing\n",
    "\n",
    "purposes, and multi node cluster with single master and multiple worker nodes would help.\n",
    "\n",
    "Again kubeadm is an appropriate tool. Or if on managed cloud environments, then quickly provision a\n",
    "\n",
    "cluster on GCP, AWS or AKS on Azure. Let’s talk about\n",
    "\n",
    "production level clusters. For hosting production grade applications.\n",
    "\n",
    "a High Availability Multi node cluster with multiple master nodes is recommended.\n",
    "\n",
    "We look at more details about High Availability setup with multiple-master nodes later in this section.\n",
    "\n",
    "Again this can be setup with kubeadm or GCP or using kops on AWS or other supported platforms.\n",
    "\n",
    "You can have upto 5000 nodes in the cluster, a total of 150k PODs in the cluster,\n",
    "\n",
    "300,000 containers in total and upto 100 PODs per node. Depending on the size of your\n",
    "\n",
    "cluster.\n",
    "\n",
    "the resource requirement for your nodes varies. CSPs like GCP and AWS automatically\n",
    "\n",
    "selects the right sized nodes for you based on the number of nodes in the cluster.\n",
    "\n",
    "This table shows the size of the instances and their resource specifications for a specific number of\n",
    "\n",
    "nodes.\n",
    "\n",
    "If you are deploying on prem nodes then you could probably start with these numbers as base. Cloud or\n",
    "\n",
    "Onprem?\n",
    "\n",
    "We have already discussed that all of these deployment options are available in any environment. For\n",
    "\n",
    "on-prem\n",
    "\n",
    "kubeadm is a very useful tool.\n",
    "\n",
    "Google Container engine makes provisioning kubernetes clusters on GCP very easy.\n",
    "\n",
    "It comes with one-click cluster upgrade features that makes it very easy to maintain the cluster. KOPS\n",
    "\n",
    "is a nice tool to deploy kubernetes cluster on AWS and the Azure Kubernetes Service or AKS\n",
    "\n",
    "helps in managing the hosted kubernetes environment on Azure. Depending on the workloads configured, your\n",
    "\n",
    "node and disk configurations will differ. For High Performance workloads rely on SSD Backed Storage. For\n",
    "\n",
    "multiple concurrent access\n",
    "\n",
    "consider network based storage. For shared access to volumes across multiple PODs,\n",
    "\n",
    "Consider persistent storage volumes that we discussed in the storage section.\n",
    "\n",
    "Consider defining different classes of storage and allocating the right class to the right applications.\n",
    "\n",
    "The Nodes forming a kubernetes cluster can be physical or virtual\n",
    "\n",
    "In our case we will be deploying virtual machines on VirtualBox environments has nodes of our cluster.\n",
    "\n",
    "You may chose to deploy on physical machines or virtual machines or cloud environments like GCP,\n",
    "\n",
    "AWS, Azure or any other platform of your choice.\n",
    "\n",
    "We will be building a cluster with three nodes one master and two worker nodes.\n",
    "\n",
    "Now We know that master nodes are for hosting control plane components like the kube-api server, etcd\n",
    "\n",
    "server and others, while worker nodes for hosting workloads.\n",
    "\n",
    "However this is not a strict requirement.\n",
    "\n",
    "The master nodes are also considered as nodes and can host workloads. As a best practice\n",
    "\n",
    "it is recommended to dedicate master nodes for control plane components only specially in a production\n",
    "\n",
    "environment.\n",
    "\n",
    "Deployment tools like kubeadm prevent workloads from being hosted on master nodes by adding a taint to\n",
    "\n",
    "the master node.\n",
    "\n",
    "You must use 64 bit Linux operating system for nodes.\n",
    "\n",
    "Another thing to note is that typically you have all the control plane components on the master nodes.\n",
    "\n",
    "However, in large clusters you may chose to separate the ETCD clusters from the master node to its\n",
    "\n",
    "own cluster nodes.\n",
    "\n",
    "We will discuss more about the different topologies for that in the upcoming lecture\n",
    "\n",
    "when we talk about high availability setup. Well those are some of the considerations for designing a\n",
    "\n",
    "kubernetes cluster.\n",
    "\n",
    "Refer to the links in the references section for more details and some interesting reads.\n",
    "\n",
    "Well that's it for this lecture.\n",
    "\n",
    "Before you go from our certification exam standpoint there's really nothing much you need to remember\n",
    "\n",
    "from this section.\n",
    "\n",
    "You don't have to memorize the numbers that we discussed as these are available in the documentation\n",
    "\n",
    "page well we'll get into more interesting topics in the upcoming lectures in this section where we will\n",
    "\n",
    "provision an actual cluster from scratch by ourselves.\n",
    "\n",
    "Well that's it for this lecture.\n",
    "\n",
    "I'll see you in the next election.\n",
    "\n",
    "\n",
    "\n",
    "## 165. Choosing Kubernetes Infrastructure\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296184#overview\n",
    "\n",
    "Hello and welcome to this lecture. In this lecture we talk about the different choices available\n",
    "\n",
    "for the infrastructure hosting a Kubernetes cluster. In the previous lecture we discussed about the various\n",
    "\n",
    "options we have in deploying a kubernetes cluster.\n",
    "\n",
    "Let's look at it in a bit more detail here.\n",
    "\n",
    "Kubernetes can be deployed on various systems in different ways. Starting with your laptops, to physical\n",
    "\n",
    "or virtual servers within an organization as well as those in the cloud.\n",
    "\n",
    "Depending on your requirements your cloud ecosystem and the kind of applications you wish to deploy\n",
    "\n",
    "you may choose one of these solutions. On a laptop or a local machine,\n",
    "\n",
    "There are a number of ways to get started.\n",
    "\n",
    "First of all on a supported Linux machine you can get started with installing the binaries manually\n",
    "\n",
    "and setting up a local cluster.\n",
    "\n",
    "However that is too tedious especially if you are just getting started.\n",
    "\n",
    "So relying on a solution that automates all that will help in setting up a cluster in a matter of minutes.\n",
    "\n",
    "We will look at some of those solutions in a bit. On Windows\n",
    "\n",
    "on the other hand, you cannot setup kubernetes natively as there are no windows binaries.\n",
    "\n",
    "You must rely on a virtualization software like Hyper-V or Vmware workstation or VirtualBox to create\n",
    "\n",
    "Linux VMs on which you can run kubernetes.\n",
    "\n",
    "There are also solutions available to run kubernetes components as docker containers on windows VMs.\n",
    "\n",
    "But remember, even then the docker images are Linux based and under the hoods they run on a small Linux OS\n",
    "\n",
    "created by Hyper-V for running Linux docker containers.\n",
    "\n",
    "So what are some of the solutions available to easily get started with kubernetes on a local machine?\n",
    "\n",
    "Minikube, deploys a single node cluster easily. It relies on one of the virtualization software like Oracle\n",
    "\n",
    "Virtualbox to create virtual machines that run the kubernetes cluster components.\n",
    "\n",
    "We have seen this in the beginners course. The kubeadm tool can be used to deploy a single node or a\n",
    "\n",
    "multi node cluster\n",
    "\n",
    "real quick before this you must provision the required hosts with supported configuration yourself.\n",
    "\n",
    "So the different between the first two and kubeadm is that the first two provisions a VM with supported\n",
    "\n",
    "configuration by itself, whereas kubeadm expects the VMs provisioned already. At the same time it allows\n",
    "\n",
    "for deploying multi-node clusters, whereas the former doesn’t. Again deploying a kubernetes cluster\n",
    "\n",
    "locally on a laptop is usually for learning, testing and development purposes. For production purposes,\n",
    "\n",
    "there are many ways to get started with a kubernetes cluster. Both in a private or a public cloud environment.\n",
    "\n",
    "I would categorize them as Turnkey solutions or Hosted or managed solutions. Turnkey solutions are where\n",
    "\n",
    "you provision the required VMs and use some kind of tools or scripts to configure kubernetes cluster\n",
    "\n",
    "on them.\n",
    "\n",
    "At the end of the day you are responsible for maintaining those VMs, and patching them and creating,upgrading\n",
    "\n",
    "them etc. But cluster management and maintenance are mostly made easy using these tools and scripts.\n",
    "\n",
    "For example deploying a kubernetes cluster on AWS using the KOPS tool. Hosted solutions are more like Kubernetes\n",
    "\n",
    "as a service solution, where the cluster along with the required VMs are deployed by the provider and\n",
    "\n",
    "kubernetes is configured by them by the provider.\n",
    "\n",
    "The VMs are maintained by the provider.\n",
    "\n",
    "For example, Google Container Engine lets you deploy a kubernetes cluster in a matter of minutes, without\n",
    "\n",
    "you having to perform any configuration by yourself. Let us look at some of the Turnkey solutions.\n",
    "\n",
    "OpenShift is a popular on-prem kubernetes platform\n",
    "\n",
    "by RedHat. For those of you who may not be familiar, OpenShift is an open source container application\n",
    "\n",
    "platform and is built on top of kubernetes.\n",
    "\n",
    "It provides a set of additional tools and a nice GUI to create and manage kubernetes constructs and\n",
    "\n",
    "easily integrate with CI/CD pipelines etc.\n",
    "\n",
    "We have an OpenShift for beginners course in our catalog.\n",
    "\n",
    "Check it out if you are interested!\n",
    "\n",
    "Cloud Foundry Container Runtime is an open-source project from Cloud Foundry that helps in deploying\n",
    "\n",
    "and managing highly available kubernetes clusters using their open-source tool called BOSH.\n",
    "\n",
    "f you wish to leverage your existing Vmware environment for kubernetes, then the Vmware Cloud\n",
    "\n",
    "PKS solution is one that should be evaluated.\n",
    "\n",
    "Vagrant provides a set of useful scripts to deploy a Kubernetes cluster on different cloud service\n",
    "\n",
    "providers.\n",
    "\n",
    "All of these solutions makes it easy to deploy and manage a cobra that is cluster privately within your\n",
    "\n",
    "organization.\n",
    "\n",
    "You must have a few Virtual Machines with supported configurations in place.\n",
    "\n",
    "These are few of the many kubernetes certified solutions.\n",
    "\n",
    "Well there are many more, so check them out in the kubernetes documentation page. Let us look at some\n",
    "\n",
    "of the hosted solutions. Google Container Engine is a very popular kubernetes as a service offering\n",
    "\n",
    "on Google Cloud Platform. Openshift online is an offering from RedHat where you can gain access to a fully\n",
    "\n",
    "functional kubernetes cluster online.\n",
    "\n",
    "Azure has Azure Kubernetes Service. And finally Amazon Elastic Container Service for Kubernetes\n",
    "\n",
    "is Amazon’s hosted kubernetes offering. Again, these are just some of the solutions\n",
    "\n",
    "there are many more. So what is our choice?\n",
    "\n",
    "In our case since this is for learning purposes and considering the fact that some of you may not have\n",
    "\n",
    "access to a public cloud account and since most of you mentioned in the poll we sent out that you prefer\n",
    "\n",
    "a local setup with Virtualbox,\n",
    "\n",
    "we chose to deploy a local kubernetes cluster from scratch on our local system by creating several\n",
    "\n",
    "virtual machines on VirtualBox.\n",
    "\n",
    "So our design now has 3 nodes, 1 master, 2 worker, to be deployed on a laptop with Virtual Machines\n",
    "\n",
    "provisioned on VirtualBox.\n",
    "\n",
    "Well that's it for this lecture.\n",
    "\n",
    "Check out the reference page to read more about many more such solutions.\n",
    "\n",
    "\n",
    "## 166. Choosing a Network Solution\n",
    "\n",
    "Depending on your environment & network ecosystem you have a wide variety of networking options to choose from. A list of supported network solutions and their implementation details are available here:\n",
    "\n",
    "https://kubernetes.io/docs/concepts/cluster-administration/networking/#how-to-implement-the-kubernetes-networking-model\n",
    "\n",
    "\n",
    "\n",
    "While choosing a network solution consider it's support for Network Policies.\n",
    "\n",
    "We chose to go with Weave as our networking solution due to its simplicity and support for Network Policies.\n",
    "\n",
    "\n",
    "\n",
    "A good read:\n",
    "\n",
    "https://www.objectif-libre.com/en/blog/2018/07/05/k8s-network-solutions-comparison/\n",
    "\n",
    "\n",
    "## 167. Configure High Availability\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296190#overview\n",
    "\n",
    "\n",
    "Hello and welcome to this lecture. We now look at high availability in kubernetes.\n",
    "\n",
    "So what happens when you lose the master node in your cluster?\n",
    "\n",
    "As long as the workers are up and containers are alive, your applications are still running.\n",
    "\n",
    "Users can access the application until things start to fail.\n",
    "\n",
    "For example a container or POD on the worker node crashes.\n",
    "\n",
    "Now, if that pod was part of a replicaset then the replication controller on the master needs to instruct\n",
    "\n",
    "the worker to load a new pod.\n",
    "\n",
    "But the Master is not available and so are the controllers and schedulers on the master.\n",
    "\n",
    "There is no one to recreate the pod and no one to schedule it on nodes.\n",
    "\n",
    "Similarly, since the kube-api server is not available you cannot access the cluster externally through\n",
    "\n",
    "kubectl tool or through API for management purposes. Which is why you must consider multiple master nodes in\n",
    "\n",
    "in a High availability configuration in your production environment. A high availability configuration is\n",
    "\n",
    "where you have redundancy across every component in the cluster so as to avoid a single point of failure.\n",
    "\n",
    "The master nodes, the worker nodes, the control plane components, the application of course, which we already\n",
    "\n",
    "have multiple copies in the form of replicasets and services.\n",
    "\n",
    "So our focus in this lecture is going to be on the master and control plane components. Let's take a\n",
    "\n",
    "better look at how it works.\n",
    "\n",
    "We’ve been looking at a 3 node cluster with 1 master and 2 worker nodes\n",
    "\n",
    "throughout this course. In this lecture, we will focus on just the master node. As we learned already the\n",
    "\n",
    "master node hosts the control plane components including the API, Controller Manager, Scheduler and ETCD\n",
    "\n",
    "server. In a HA setup, with an additional master node, you have the same components running on\n",
    "\n",
    "the new master as well.\n",
    "\n",
    "So how does that work.\n",
    "\n",
    "Running multiple instances of the same components? Are they going to do the same thing twice?\n",
    "\n",
    "How do they share the work among themselves?\n",
    "\n",
    "Well that differs based on what they do.\n",
    "\n",
    "We know that the API server is responsible for receiving requests and processing them or providing information\n",
    "\n",
    "about the cluster. They work on one request at a time.\n",
    "\n",
    "So the API servers on all cluster nodes can be alive and running at the same time in an active active\n",
    "\n",
    "mode. So far in this course\n",
    "\n",
    "we know that the kubectl utility talks to the API server to get things done\n",
    "\n",
    "and we point the kubectl utility to reach the master node at port 6443.\n",
    "\n",
    "That’s where the API server listens and this is configured in the kube-config file.\n",
    "\n",
    "Well now with 2 masters, where do we point the kubectl to?\n",
    "\n",
    "We can send a request to either one of them but we shouldn't be sending the same request to both of\n",
    "\n",
    "them.\n",
    "\n",
    "So it is better to have a load balancer of some kind configured in the front of the master nodes that\n",
    "\n",
    "split traffic between the API servers.\n",
    "\n",
    "So We then point the kubectl utility to that load balancer.\n",
    "\n",
    "You may use, NGINX or HA proxy or any other load balancer for this purpose.\n",
    "\n",
    "What about the scheduler and the controller manager.\n",
    "\n",
    "These are controllers that watch the State of the cluster and take actions. For example the controller\n",
    "\n",
    "manager consists of controllers like the replication controller that is constantly watching the state\n",
    "\n",
    "of PODs and taking necessary actions, like creating a new POD\n",
    "\n",
    "when one fails. If multiple instances of those run in parallel, then they might duplicate actions\n",
    "\n",
    "resulting in more parts than actually needed.\n",
    "\n",
    "The same is true with scheduler.\n",
    "\n",
    "As such they must not run in parallel.\n",
    "\n",
    "They run in an active standby mode.\n",
    "\n",
    "So then who decides which among the two is active and which is passive.\n",
    "\n",
    "This is achieved through a leader election process.\n",
    "\n",
    "So how does that work.\n",
    "\n",
    "Let's look at controller manager for instance. When a controller manager process is configured.\n",
    "\n",
    "You may specify the leader elect option which is by default set to true.\n",
    "\n",
    "With this option when the controller manager process starts it tries to gain a lease or a lock on an\n",
    "\n",
    "endpoint object in kubernetes named as kube-controller-manager endpoint. Which ever process first\n",
    "\n",
    "updates the endpoint.\n",
    "\n",
    "With this information gains the lease and becomes the active of the two.\n",
    "\n",
    "The other becomes passive it holds the lock for the lease duration specified using the leader-elect-lease-\n",
    "\n",
    "duration option which is by default set to 15 seconds.\n",
    "\n",
    "The active process then renews the lease every 10 seconds which is the default value for the option\n",
    "\n",
    "leader-elect-renew-deadline. Both the processes tries to become the leader every two seconds, set by\n",
    "\n",
    "the leader-elect-retry-period option.\n",
    "\n",
    "That way if one process fails maybe because the first must of crashes then the second process can acquire\n",
    "\n",
    "the lock and become the leader. The scheduler follows a similar approach and has the same command line\n",
    "\n",
    "options. Next up, ETCD.\n",
    "\n",
    "We discussed about ETCD earlier in this course.\n",
    "\n",
    "It's a good idea to go through that again now just to quickly refresh your memory as we're going to\n",
    "\n",
    "discuss some topics related to how ETCD works in this lecture. With ETCD,\n",
    "\n",
    "there are two topologies that you can configure in kubernetes.\n",
    "\n",
    "One is as it looks here and the same architecture we have been following through out this course, where\n",
    "\n",
    "ETCD is part of the kubernetes master nodes. It’s called as a stacked control plan nodes topology.\n",
    "\n",
    "This is easier to setup and easier to manage. And requires fewer nodes. But if one node goes down\n",
    "\n",
    "both an ETCD member and control plane instance is lost and redundancy is compromised. The other is\n",
    "\n",
    "where ETCD is separated from the control plane nodes and run on its own set of servers. This is a topology\n",
    "\n",
    "with external ETCD servers. Compared to the previous topology\n",
    "\n",
    "this is less risky as a failed control plane node does not impact the ETCD cluster and the data it stores.\n",
    "\n",
    "However it is harder to setup and requires twice the number of servers for the external etcd nodes. So\n",
    "\n",
    "remember, the API server is the only component that talks to the ETCD server and if you look into the\n",
    "\n",
    "API service configuration options, we have a set of options specifying where the ETCD server is.\n",
    "\n",
    "So regardless of the topology we use and wherever we configure ETCD servers, weather on the same server\n",
    "\n",
    "or on a separate server.\n",
    "\n",
    "ultimately we need to make sure that the API server is pointing to the right address of the ETCD servers.\n",
    "\n",
    "Now remember ETCD is a distributed system, so the API server or any other component that wishes to talk\n",
    "\n",
    "to it, can reach the ETCD server at any of its instances.\n",
    "\n",
    "You can read and write data through any of the available ETCD server instances.\n",
    "\n",
    "This is why we specify a list of etcd-servers in the kube-apiserver configuration. In the next lecture\n",
    "\n",
    "we discuss more about how ETCD server works in a cluster setup and the best practices around the number\n",
    "\n",
    "of recommended nodes in a cluster.\n",
    "\n",
    "So back to our design we had originally planned for a single master node in our cluster.\n",
    "\n",
    "Now with HA, we decided to configure multiple masters.\n",
    "\n",
    "We also mentioned about a load balancer for the API server. So we will have that as well.\n",
    "\n",
    "So we now have a total of five nodes in our cluster.\n",
    "\n",
    "\n",
    "\n",
    "## 168. ETCD in HA\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296192#overview\n",
    "\n",
    "Hello and welcome to this lecture. In this lecture\n",
    "\n",
    "we'll talk about ETCD in a high availability setup.\n",
    "\n",
    "So this is really a prerequisite lecture for the next lecture where we talk about configuring Kubernetes\n",
    "\n",
    "in a highly available mode.\n",
    "\n",
    "Well one portion of that deals with configuring ETCD in HA mode.\n",
    "\n",
    "So in this lecture we will discuss about ETCD in HA mode in the beginning of this course we took\n",
    "\n",
    "a quick look at ETCD.\n",
    "\n",
    "We will now recap real quick and more importantly focus on the cluster configuration on ETCD.\n",
    "\n",
    "So let’s recap real quick and look at the number of nodes in the cluster, what RAFT protocol is etc.\n",
    "\n",
    "So what is ETCD?\n",
    "\n",
    "It's a distributed reliable key value store that is simple secure and fast.\n",
    "\n",
    "So let's break it up.\n",
    "\n",
    "Traditionally data was organized and stored in tables like this.\n",
    "\n",
    "For example to store details about a number of individuals. A key value store stores information in the\n",
    "\n",
    "form of documents or pages.\n",
    "\n",
    "So each individual gets a document and all information about that individual is stored within that file.\n",
    "\n",
    "These files can be in any format or structure and changes to one file does not affect the others.\n",
    "\n",
    "In this case the working individuals can have their files with salary fields. While you could store and\n",
    "\n",
    "retrieve simple key and values when your data gets complex.\n",
    "\n",
    "you typically end up transacting in data formats like JSON or YAML.\n",
    "\n",
    "So that’s what etcd is and how you quickly get started with it.\n",
    "\n",
    "We also said that ETC is distributed.\n",
    "\n",
    "So what does that mean.\n",
    "\n",
    "And that is what we're going to focus in this lecture.\n",
    "\n",
    "We had ETCD on a single server. But it’s a database and may be storing critical data.\n",
    "\n",
    "So it is possible to have your datastore across multiple servers.\n",
    "\n",
    "Now you have 3 servers, all running etcd, and all maintaining an identical copy of the database.\n",
    "\n",
    "So if you lose one you still have two copies of your data.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "But how does it ensure the data on all the nodes are consistent.\n",
    "\n",
    "You can write to any instance and read your data from any instance. ETCD ensures that the same consistent\n",
    "\n",
    "copy of the data is available on all instances at the same time.\n",
    "\n",
    "So how does it do that? With reads,\n",
    "\n",
    "its easy. Since the same data is available across all nodes,\n",
    "\n",
    "you can easily read it from any nodes. But that is not the case with writes.\n",
    "\n",
    "What if two write requests come in on two different instances? Which one goes through?\n",
    "\n",
    "For example I have writes coming in for name set to john on one and with the name joe on the other.\n",
    "\n",
    "Of course we cannot have two different data on two different nodes.\n",
    "\n",
    "When I said ETCD can write through any instance, I wasn’t a 100% right.\n",
    "\n",
    "ETCD does not process the writes on each node.\n",
    "\n",
    "Instead, only one of the instances is responsible for processing the writes. Internally\n",
    "\n",
    "the two nodes elect a leader among them. Of the total instances one node becomes the leader and the other\n",
    "\n",
    "node becomes the followers.\n",
    "\n",
    "If the writes came in through the leader node, then the leader processes the write. The leader makes sure\n",
    "\n",
    "that the other nodes are sent a copy of the data.\n",
    "\n",
    "If the writes come in through any of the other follower nodes, then they forward the writes to the leader\n",
    "\n",
    "internally and then the leader processes the writes. Again\n",
    "\n",
    "when the writes are processed, the leader ensures that copies of the write and distributed to other instances\n",
    "\n",
    "in the cluster.\n",
    "\n",
    "Thus a write is only considered complete, if the leader gets consent from other members in the cluster.\n",
    "\n",
    "So how do they elect the leader among themselves? And how do they ensure a write is propogated across\n",
    "\n",
    "all instances? ETCD implements distributed consensus using RAFT protocol.\n",
    "\n",
    "Let's see how that works in a three node cluster.\n",
    "\n",
    "When the cluster is setup we have 3 nodes that do not have a leader elected. RAFT algorithm uses\n",
    "\n",
    "random timers for initiating requests.\n",
    "\n",
    "For example a random timer is kicked off on the three managers the first one to finish the timer sends\n",
    "\n",
    "out a request to the other node requesting permission to be the leader. The other managers on receiving\n",
    "\n",
    "the request responds with their vote and the node assumes the Leader role. Now that it is elected the\n",
    "\n",
    "leader it sends out notification at regular intervals to other masters informing them that it is continuing\n",
    "\n",
    "to assume the role of the leader. In case the other nodes do not receive a notification from the leader\n",
    "\n",
    "at some point in time which could either be due to the leader going down or losing network connectivity\n",
    "\n",
    "the nodes initiate a re-election process among themselves and a new leader is identified going back\n",
    "\n",
    "to our previous example where a right come seen it is processed by the leader and is replicated to other\n",
    "\n",
    "nodes in the cluster the right is considered to be complete only once it is replicated to the other\n",
    "\n",
    "instances in the cluster.\n",
    "\n",
    "We said that the ETCD cluster is highly available. So even if we lose a node it should still function.\n",
    "\n",
    "Say for example a new write comes in but one of the node is not responding. And hence the leader is only\n",
    "\n",
    "able to write to 2 nodes in the cluster. Is the write considered to be complete? Does it wait for the\n",
    "\n",
    "third node to be up? Or does it fail? A write is considered to be complete,\n",
    "\n",
    "if it can be written on the majority of the nodes in the cluster. For example, in this case of the 3 nodes,\n",
    "\n",
    "the majority is 2.\n",
    "\n",
    "So if the data can be written on two of the nodes then the right is considered to be complete.\n",
    "\n",
    "If the third node was to come on line then the data is copied to that as well.\n",
    "\n",
    "So what is the majority.\n",
    "\n",
    "Well a more appropriate term to use would be Quorum. Quorum is the minimum number of nodes that must\n",
    "\n",
    "be available for the cluster to function properly or make a successful right in case of 3.\n",
    "\n",
    "we know its 2. For any given number of nodes, the quorum is the total number of nodes divided by 2 + 1.\n",
    "\n",
    "So Quorum of 3 nodes is 3/2 which is 1.5 + 1 equals 2.5.\n",
    "\n",
    "If there is a .5 consider the whole number only so that's 2.\n",
    "\n",
    "Similarly quorum of 5 nodes is 3.\n",
    "\n",
    "So here is a table that shows the quorum of clusters of size 1 to 7. Quorum of 3 and 5 are what\n",
    "\n",
    "we calculated. Quorum of 1 is 1 itself.\n",
    "\n",
    "Meaning if you have a single non cluster none of these really apply.\n",
    "\n",
    "If you lose that note everything's gone if you look at 2 and apply the same formula.\n",
    "\n",
    "the quorum is 2 itself. 2/2 is 1 and 1 + 1 is 2.\n",
    "\n",
    "So even if you have 2 instances in the cluster the majority is still 2. If one fails,\n",
    "\n",
    "There is no quorum.\n",
    "\n",
    "So rates won't be processed.\n",
    "\n",
    "So having two instances is like having one instance it doesn't offer you any real value as quorum cannot\n",
    "\n",
    "be met.\n",
    "\n",
    "Which is why it is recommended to have a minimum of 3 instances in an ETCD cluster. That way\n",
    "\n",
    "it offers a fault tolerance of at least 1 node.\n",
    "\n",
    "If you lose one, you can still have quorum and the cluster will continue to function.\n",
    "\n",
    "So the first column minus the second column gives you the fault tolerance. The number of nodes that you\n",
    "\n",
    "can afford to lose while keeping the cluster alive.\n",
    "\n",
    "So we have 1 to 7 nodes here. 1 and 2 are out of consideration.\n",
    "\n",
    "So from 3 to 7 what do we consider?\n",
    "\n",
    "As you can see 3 and 4 have the same fault tolerance of 1 and 5 and 6 have the same fault\n",
    "\n",
    "tolerance of 2. When deciding on the number of master nodes,it is recommended to select an odd number\n",
    "\n",
    "as highlighted in the table 3 or 5 or 7. Say we have a 6 node cluster.\n",
    "\n",
    "So for example due to a disruption in the network it fails and causes the network to partition.\n",
    "\n",
    "We have 4 nodes on one and 2 on the other.\n",
    "\n",
    "In this case the group with 4 nodes have quorum and continues to operate normally. However if the\n",
    "\n",
    "network got partitioned in a different way resulting in nodes being distributed equally between the two,\n",
    "\n",
    "each group now has 3 nodes only.\n",
    "\n",
    "But since we originally had 6 manager nodes, the quorum for the cluster to stay alive is 4\n",
    "\n",
    "But if you look at the groups here neither of these groups have four managers to meet the quorum so\n",
    "\n",
    "it results in a failed cluster.\n",
    "\n",
    "So with even number of nodes there is possibility of the cluster failing during a network segmentation.\n",
    "\n",
    "In case we had odd number of managers originally, say 7,\n",
    "\n",
    "then after the network segmentation we have 4 on one segmented network and 3 on the other,\n",
    "\n",
    "and so our cluster still lives on the group with 4 managers as it meets the quorum of 4.\n",
    "\n",
    "No matter how the network segments there are better chances for your cluster to stay alive in case of\n",
    "\n",
    "network segmentation with odd number of nodes.\n",
    "\n",
    "So an odd number of nodes is preferred over even number having 5 is preferred over 6 and having\n",
    "\n",
    "more than 5 nodes is really not necessary as 5 gives you enough for tolerance. To install ETCD on\n",
    "\n",
    "a server.\n",
    "\n",
    "download the latest supported binary. Extract it,\n",
    "\n",
    "create the required directory structure. Copy over the certificate files generated for ETCD. We\n",
    "\n",
    "discussed how to generate these certificates in detail in the TLS Certificates section. Then configure\n",
    "\n",
    "the ETCD service.\n",
    "\n",
    "What's important here is to note that the initial cluster option where we passing the peer's information\n",
    "\n",
    "That’s how each etcd service knows that it is part of a cluster and where its peers are. Once installed\n",
    "\n",
    "and configured use the etcdctl utility to store and retrieve data. ETCDCTL utility has\n",
    "\n",
    "two API versions.\n",
    "\n",
    "V2 and V3. So the commands work different in each version.\n",
    "\n",
    "Version 2 is default.\n",
    "\n",
    "However we will use version 3. So set an environment variable\n",
    "\n",
    "ETCDCTL_API to 3, otherwise the below commands won’t work.\n",
    "\n",
    "Run the etcdctl put command and specify the key as name and value as john. To retrieve data from\n",
    "\n",
    "the etcdctl\n",
    "\n",
    "get command with the key /name and it returns the value john.To get all keys run the etcdctl\n",
    "\n",
    "get –keys-only\n",
    "\n",
    "command. Going back to our design,\n",
    "\n",
    "how many nodes, should our cluster have? In an HA environment\n",
    "\n",
    "as you can see having 1 or 2 instances doesn’t really make any sense. As losing 1 node, in either\n",
    "\n",
    "case will leave you without quorum and thus render the cluster not functional. Hence the minimum required\n",
    "\n",
    "nodes in an HA setup is 3.\n",
    "\n",
    "We also discussed why we prefer odd number of instances over even number. Having even number of instances\n",
    "\n",
    "can leave the cluster without quorum in certain network partition scenarios.\n",
    "\n",
    "So all that even number of nodes is out of scope. So we are left with 3 5 and 7 or any odd number above\n",
    "\n",
    "that 3 is a good start but if you prefer a higher level of full tolerance then 5 is better. But anything\n",
    "\n",
    "beyond that is just unnecessary.\n",
    "\n",
    "So considering your environment the fault tolerance requirements and the cost that you can bear you\n",
    "\n",
    "should be able to choose one number from this list.\n",
    "\n",
    "In our case we go with 3.\n",
    "\n",
    "So how does our design look now? With HA,\n",
    "\n",
    "the minimum required number of nodes for fault tolerance is 3.\n",
    "\n",
    "Now while it would be great to have 3 master nodes we are limited by our capacity of our laptop. So we\n",
    "\n",
    "will just go with 2.\n",
    "\n",
    "But if you're deploying the setup in another environment and have sufficient capacity feel free to go\n",
    "\n",
    "with 3.\n",
    "\n",
    "We also chose to go with the stacked topology where we will have the ETCD servers on the master nodes\n",
    "\n",
    "itself.\n",
    "\n",
    "Well that's it for this lecture.\n",
    "\n",
    "Thank you for listening.\n",
    "\n",
    "I will see you in the next.\n",
    "\n",
    "\n",
    "## 169. \"Kubernetes the Hard Way\" on VirtualBox\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14366396#overview\n",
    "\n",
    "Here is the link to my customized version of \"Kubernetes the Hard Way\" on VirtualBox\n",
    "\n",
    "\n",
    "\n",
    "https://github.com/mmumshad/kubernetes-the-hard-way\n",
    "\n",
    "\n",
    "\n",
    "## 170. Demo - Pre-Requisites\n",
    "\n",
    "Hello and welcome to this demo.\n",
    "\n",
    "In this demo we will see how to set up our environment and the prerequisites required to deploy a\n",
    "\n",
    "kubernetes cluster from scratch.\n",
    "\n",
    "All the instructions required to deploy this cluster is recorded in the github repository here.\n",
    "\n",
    "Check out the link to this repository in the resources section.\n",
    "\n",
    "This is a fork of the original one developed by Kelsey Hightower.\n",
    "\n",
    "That was for deploying a Kubernetes cluster from scratch on GCP. So I forked it and modified it\n",
    "\n",
    "to be deployed on a virtual box environment on local machine.\n",
    "\n",
    "I have also updated it to use the latest stable version of kubernetes\n",
    "\n",
    "as of this recording, which is v1.13. I have also added some additional details on TLS\n",
    "\n",
    "bootstrapping a kubelet and end-to-end tests. I have recorded the differences between the original and this\n",
    "\n",
    "in a file on this repo.\n",
    "\n",
    "You can perform these on windows, Linux or mac systems.\n",
    "\n",
    "It doesn't matter what OS you're using. As long as it is 64 bit, and virtualization is enabled you should\n",
    "\n",
    "be good.\n",
    "\n",
    "The first step is to clone this repository. So you must have git for this. So run the git clone command.\n",
    "\n",
    "Copy the git repository url from github and paste it here.\n",
    "\n",
    "Once cloned CD into the cloned directory. The reason we cloned this git repository is because it has the\n",
    "\n",
    "scripts necessary to deploy the required infrastructure within it that we will use in the next demo.\n",
    "\n",
    "We will now look at the prerequisites for this exercise.\n",
    "\n",
    "As I said before, you may follow these instructions to deploy a kubernetes environment from scratch\n",
    "\n",
    "on a local laptop or a physical or virtual machine in your environment whatever system you choose.\n",
    "\n",
    "It should have virtualization capability and sufficient resources like CPU, Memory and Disk.I have\n",
    "\n",
    "specified 8 GB as minimum RAM.\n",
    "\n",
    "We plan to allocate a memory of 1 TB to each master node and 500 megabytes to the worker nodes and load\n",
    "\n",
    "balancers.\n",
    "\n",
    "But it also depends on the memory consumption on your system.\n",
    "\n",
    "So a higher RAM will always help. Regarding disk space 50 to 100 GB of free space would be good.\n",
    "\n",
    "just to show you the system I'm using.\n",
    "\n",
    "I have a Intel i7-6500U CPU @ 2.5GHz with 2 cores and 4 Logical\n",
    "\n",
    "processors. And a memory of 32 GB.\n",
    "\n",
    "The next step is to install virtual box.\n",
    "\n",
    "Click on this link to go to the VirtualBox download page.\n",
    "\n",
    "As you can see it is supported on almost any platforms, windows, OSX, Linux or Solaris.\n",
    "\n",
    "Download the appropriate package and install virtual box.\n",
    "\n",
    "I have virtual box installed already. I use version 5.2.6\n",
    "\n",
    "The next step is to install Vagrant. Vagrant is used to automate the deployment of virtual machines,\n",
    "\n",
    "our case on virtual box.\n",
    "\n",
    "Again click on this link to go to the Vagrant site.\n",
    "\n",
    "Download the right version of your OS.\n",
    "\n",
    "I have it already installed. I am at version 2.1.1.\n",
    "\n",
    "We now have our environment ready to begin deployment.\n",
    "\n",
    "Well that's it for this demo.\n",
    "\n",
    "I will see you the next.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 171. Demo - Provision VMS\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296214#overview\n",
    "\n",
    "\n",
    "Hello and welcome to this lecture.\n",
    "\n",
    "In this lecture we will discuss about Provisioning Infrastructure for Kubernetes. Depending on your choice\n",
    "\n",
    "of infrastructure for kubernetes and HA preferences, deploy the required infrastructure as\n",
    "\n",
    "planned. In our case we decided to provision infrastructure on VirtualBox VMs.\n",
    "\n",
    "In our case we are going to provision a 5 node VM, with just 1 vCPU each and 1 GB of memory\n",
    "\n",
    "on each.\n",
    "\n",
    "Well in fact for the worker nodes as well as the load balancer you can take down the memory requirements\n",
    "\n",
    "to 500 megabytes. We can either just provision the required infrastructure manually one by one or use\n",
    "\n",
    "some kind of automation tool like Vagrant. If you use VirtualBox and haven’t explored Vagrant, I\n",
    "\n",
    "highly recommend that you do.\n",
    "\n",
    "It’s very easy to get started with. We will be using Vagrant\n",
    "\n",
    "in this example. I have a veteran file that deploys to set up with a single command so we can all ensure\n",
    "\n",
    "we have the same setup to work with.\n",
    "\n",
    "This will deploy 5 VMs, 2 for Master, 2 Workers, 1 loadbalancer.\n",
    "\n",
    "It assigns the IP addresses to each of them. It adds DNS entries so they can reach the Internet. And finally\n",
    "\n",
    "install Docker on them.\n",
    "\n",
    "So let's see this in action in this demo.\n",
    "\n",
    "we will see how to provision the required VMs on VirtualBox using Vagrant. The vagrant file that\n",
    "\n",
    "automates the creation of these VMs is already available in the vagrant directory. So CD into the\n",
    "\n",
    "vagrant directory and run the vagrant up command.\n",
    "\n",
    "This will provision all the required VMs. They are all Ubuntu bionic VMs,\n",
    "\n",
    "they get IP addresses in the subnet 192.168.5. as specified here. On the worker nodes it instal\n",
    "\n",
    "Docker version 18.06 and also enables IP bridge forwarding. So we will do that now\n",
    "\n",
    "On the left you see a command prompt windows. On the right\n",
    "\n",
    "you see the VirutalBox with no VMs. CD into the vagrant directory and run vagrant up command.\n",
    "\n",
    "On the right\n",
    "\n",
    "you see the VMs getting deployed.\n",
    "\n",
    "It takes about 10 minutes for the environment to be ready depending on your system and network resources\n",
    "\n",
    "available.\n",
    "\n",
    "Okay.\n",
    "\n",
    "So we're done with the deployment and all VMs are up now.\n",
    "\n",
    "We will now look at how to access these VMs. In the directory from where you ran the vagrant up command\n",
    "\n",
    "There will be a .vagrant hidden directory.\n",
    "\n",
    "This is where the private_keys required to access the VMs are stored.\n",
    "\n",
    "There is a folder for each VM and within that the private key is stored under the virtual box folder.\n",
    "\n",
    "We will use this to SSH to the nodes.\n",
    "\n",
    "The first way is to ssh using vagrant itself. Vagrant ssh command can be used to SSH to the node\n",
    "\n",
    "like this.\n",
    "\n",
    "This way you don’t have to explicitly specify the private_key. Or you can use any SSH terminal tool to\n",
    "\n",
    "ssh to the worker nodes. Such as Putty. In my case I use something called as MobaXTerm.\n",
    "\n",
    "Now you don't have to use the same.\n",
    "\n",
    "You may perform these steps on your favorite terminal.\n",
    "\n",
    "Just make sure you use the right SSH Private_key.\n",
    "\n",
    "At the end of the day, you should be able to easily access the nodes.\n",
    "\n",
    "In my case.\n",
    "\n",
    "I create a folder for this project.\n",
    "\n",
    "I’ll group the sessions within it. I then create a new SSH session,\n",
    "\n",
    "use the IP of the master which is 192.168.5.11,\n",
    "\n",
    "The user name is vagrant and the path to the private key the session name is going to be master dash\n",
    "\n",
    "one.\n",
    "\n",
    "Ensure you are able to SSH into it. Repeat the same steps for the other nodes.\n",
    "\n",
    "well that's it for this demo in the upcoming demo.\n",
    "\n",
    "We will carry on from here and we will move on to the rest of the configuration for the cluster.\n",
    "\n",
    "\n",
    "## 172. Demo - Install Client Tools\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296218#overview\n",
    "\n",
    "Once we provision the infrastructure the next step is to identify an administrative client for performing\n",
    "\n",
    "some administrative tasks, such as creating certificates, kubeconfig files and distributing them to the\n",
    "\n",
    "other nodes.\n",
    "\n",
    "You may choose your local laptop for this.\n",
    "\n",
    "In my case I chose to use master-1 as my administrative client. Whatever system you chose\n",
    "\n",
    "make sure that system has SSH access to all other systems, so you can copy files over easily\n",
    "\n",
    "to enable copy of files from this system\n",
    "\n",
    "we setup SSH key based authentication to the other systems from the master-1 node. We create an SSH key pair\n",
    "\n",
    "and distribute the public key to the other systems.\n",
    "\n",
    "For this we create an SSH key pair on the master-1 node using the ssh-key gen command.\n",
    "\n",
    "Leave all default options. View the public key at .ssh directory and the file name is\n",
    "\n",
    ".ssh/id_rsa.pub.\n",
    "\n",
    "copy its contents and add it to the authorized keys file.\n",
    "\n",
    "on the other nodes. I have this command snippet here which you can use. Replace the public key inside\n",
    "\n",
    "it and execute that command on all other nodes.\n",
    "\n",
    "We will now test to see if that works.\n",
    "\n",
    "We should be able to simply ssh to master-2 and see that it works.\n",
    "\n",
    "well it does so we will repeat the same on all the other nodes.\n",
    "\n",
    "Finally we need the kubectl utility to be installed on this system, to generate kubeconfig files.\n",
    "\n",
    "So which ever is your administrative client, download the kubeconfig file and configure it as an executable.\n",
    "\n",
    "Well that's it for this demo.\n",
    "\n",
    "\n",
    "## 173. Demo - Secure Cluster\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296224#overview\n",
    "\n",
    "Hello and welcome to this demo.\n",
    "\n",
    "In this demo we look at securing communication within the cluster using TLS certificates.\n",
    "\n",
    "We discussed about certificates extensively and how to generate these certificates during the TLS\n",
    "\n",
    "section in the course earlier.\n",
    "\n",
    "So it should be easy for us to execute this part. I have the screen divided into two here.\n",
    "\n",
    "The terminal on the left and documentation on the right.\n",
    "\n",
    "That way I can easily copy and paste commands.\n",
    "\n",
    "The instructions are documented in the section named : provisioning the CA and generating TLS certificates.\n",
    "\n",
    "So you can do these tasks on the system that you have identified as your administrative client\n",
    "\n",
    "In my case it’s the master-1 node. Whichever system you chose\n",
    "\n",
    "make sure that system has SSH access to all other systems so you can copy files over.\n",
    "\n",
    "We start with Certificate Authority. Run the OpneSSL genrsa command to generate private key\n",
    "\n",
    "for CA Then create a certificate signin request with the name set to kubernetes-CA. Then\n",
    "\n",
    "self sign the CA certificate.\n",
    "\n",
    "We are left with ca.crt and ca.key file. Ignore the csr file.\n",
    "\n",
    "Next we create the admin certification. Generate the private key,\n",
    "\n",
    "then generate CSR. Remember to add the name as admin and group as system:masters.\n",
    "\n",
    "Finally sign the certificate using the CA key pairs.\n",
    "\n",
    "We now have the admin key and certificate.\n",
    "\n",
    "Next follow the same procedure for controller manager\n",
    "\n",
    "And then kube-proxy.\n",
    "\n",
    "And then the scheduler.\n",
    "\n",
    "We now generate the ones for the kube-api server.\n",
    "\n",
    "Now remember the kube-api server certificate must have all names that the kube-apiserver goes by.\n",
    "\n",
    "So we create a separate configuration file first, specify all names. Then generate the certificate\n",
    "\n",
    "sending request with that file as an option and finally sign the certificate using the CAs key pairs\n",
    "\n",
    "Then we head over to ETCD.\n",
    "\n",
    "Again we follow the same procedure of creating a configuration file.\n",
    "\n",
    "We will name the ETCD certificaet etcd-server. Generate CSR and signing request.\n",
    "\n",
    "Finally, the kubernetes controller manager leverages a key pair to generate and sign service account\n",
    "\n",
    "tokens.\n",
    "\n",
    "For that we create a certificate pair for service-accounts. So we are now done with all the control plane\n",
    "\n",
    "certificates.\n",
    "\n",
    "We still haven't done the certificates for the kubelets for the worker nodes.\n",
    "\n",
    "We will do that later when we configure the worker nodes.\n",
    "\n",
    "We then distribute the certificates to the other master nodes so if you have more than 2 master nodes\n",
    "\n",
    "move these two all of them.\n",
    "\n",
    "If you're doing this on the first master then you can really remove the first master node from this\n",
    "\n",
    "command.\n",
    "\n",
    "But I'll just leave it as is. We have now generated all the required certificates and moved\n",
    "\n",
    "them to the right nodes, except for the worker.\n",
    "\n",
    "We are now ready to go ahead with the master nodes installation and configuration.\n",
    "\n",
    "\n",
    "## 174. Demo - Kube config Files\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296226#overview\n",
    "\n",
    "We talked about kubeconfig files earlier in this course.\n",
    "\n",
    "It is used by clients to access the kube-api server.\n",
    "\n",
    "It has information about the api server and the required credentials within it.\n",
    "\n",
    "The admin user, controller-manager, scheduler, kubeproxy are all clients to the kube-api server. So they\n",
    "\n",
    "all use kubeconfig files to communicate with the kubeapi server.\n",
    "\n",
    "In this demo we will see how to generate kube config files for this purpose.\n",
    "\n",
    "The process is documented under the section named - Generating Kubernetes Configuration Files for Authentication.\n",
    "\n",
    "As you can see here, we will be creating kubeconfig files for kube-proxy which will run on the worker\n",
    "\n",
    "nodes, The kube-controller-manager, scheduler and the admin user.\n",
    "\n",
    "And finally we distribute it to the other nodes\n",
    "\n",
    "Remember, in our design we talked about configuring the load balancer in front of the master nodes for\n",
    "\n",
    "the API server.\n",
    "\n",
    "Note here that the components that live with the kube-api server on the same master nodes, such as the\n",
    "\n",
    "controller-manager and scheduler can reach the api-server directly at the loopback address of 127.0.0.1.\n",
    "\n",
    "Whereas those outside the master nodes, such as the admin user, the kube-proxy reach the api-server\n",
    "\n",
    "through the load balancer. So configure the kubeconfig files accordingly.\n",
    "\n",
    "First we set the loadblanacer address that will be used within the kubeconfig files. We start\n",
    "\n",
    "the kubeproxy\n",
    "\n",
    "then proceed to the controller manager\n",
    "\n",
    "then the scheduler\n",
    "\n",
    "and finally the one for the admin user.\n",
    "\n",
    "Finally we copy over those to the required nodes. The kube-proxy goes to the worker nodes. The rest of\n",
    "\n",
    "them goes to the master notes.\n",
    "\n",
    "Note that we haven't created the kubeconfig file to be used by the kubelets on the worker nodes.\n",
    "\n",
    "I am leaving that out\n",
    "\n",
    "as of now. We will do that when we configure the worker nodes. I am leaving out all the worker node related\n",
    "\n",
    "activities to later so we have all of those tasks together in one place and we'll be looking at two\n",
    "\n",
    "ways of bootstrapping a worker node so it will help us compare the two approaches.\n",
    "\n",
    "\n",
    "## 175. Demo - Data encryption\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296230#overview\n",
    "\n",
    "In this demo, we look at generating the data encryption config and key. Kubernetes stores all of its data\n",
    "\n",
    "about the cluster, applications and secrets in ETCD data store. To store this data in an encrypted\n",
    "\n",
    "format\n",
    "\n",
    "you must generate an encryption key. First create an encyprtion key and then create a n encryption config\n",
    "\n",
    "file using that key.\n",
    "\n",
    "We will use this configuration file when we configure the kube-apiserver.\n",
    "\n",
    "For now we distribute this file to the master\n",
    "\n",
    "Nodes\n",
    "\n",
    "well that's it for this demo.\n",
    "\n",
    "\n",
    "## 176. Demo - Install the ETCD cluster on the master nodes\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296232#overview\n",
    "\n",
    "We are now ready to deploy the master plan components.\n",
    "\n",
    "We start with the ETCD cluster.\n",
    "\n",
    "We decided to deploy a stacked topology where we deploy ETCD cluster on the master nodes itself.\n",
    "\n",
    "But you may chose to follow the same steps to deploy an external ETCD cluster as well.\n",
    "\n",
    "We are deploying ETCD as a cluster.\n",
    "\n",
    "We will need to follow the same procedure on all ETCD nodes, in this case all our master nodes. I have\n",
    "\n",
    "established SSH connection to both the master nodes. My SSH client has a feature that helps in\n",
    "\n",
    "simultaneously executing commands on two terminal sessions. So a type of command in one and it automatically\n",
    "\n",
    "replicates that on the other.\n",
    "\n",
    "There are many other solutions for this as well.\n",
    "\n",
    "Or you can just manually execute these commands on each node way yourself.\n",
    "\n",
    "Well it doesn't really matter.\n",
    "\n",
    "First we download the ETCD binary.\n",
    "\n",
    "I run this command on both the servers. It downlaods the binaries.\n",
    "\n",
    "Next extract the etcd server\n",
    "\n",
    "Then configure the etcd server. We first create the folder structure for ETCD and then move the certificate\n",
    "\n",
    "files and keys we created earlier to the required folder. For configuring the ETCD server service\n",
    "\n",
    "we need the internal IP address of the VMs. So I'll use this oneliner to fetch that. Or you can jus\n",
    "\n",
    "set it manually on each terminal.\n",
    "\n",
    "Verify that it's got the right IP\n",
    "\n",
    "Next set the ETCD_NAMe to the hostname of the vm.\n",
    "\n",
    "Just make sure it's got the right values to\n",
    "\n",
    "We now configure the ETCD service.\n",
    "\n",
    "Note that it has the path to the certificate files we created as well as the Ips of the members\n",
    "\n",
    "in the cluster, the master-1 and master-2 nodes.\n",
    "\n",
    "That's how it knows that it is part of a cluster and those are the other members of the cluster.\n",
    "\n",
    "Just verify its got the correct details on each of them.\n",
    "\n",
    "reload enable and start the service check the status of the service and make sure it's active\n",
    "\n",
    "to verify that it's working correctly.\n",
    "\n",
    "use the ETCDCTL utility and list the members. It should list two members part of the cluster.\n",
    "\n",
    "Well that's it for this demo.\n",
    "\n",
    "\n",
    "\n",
    "## 177. Demo - Install Control Plane Components\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296238#overview\n",
    "\n",
    "The next step is to install control plane components.\n",
    "\n",
    "We will again execute these tasks on both the master nodes.\n",
    "\n",
    "We start by creating a directory for kubernetes configuration.\n",
    "\n",
    "Then download the kubernetes binaries\n",
    "\n",
    "this includes the kube-apiserver binary, the kube-controller-manager binary, the kube-scheduler binary\n",
    "\n",
    "and the kubectl binary.\n",
    "\n",
    "Once downloaded make them executable and move them to the bin directory.\n",
    "\n",
    "Move the certificates and encryption key config file to the /var/lib/kubernetes location.\n",
    "\n",
    "Again get the internal IP of the system or set it manually.\n",
    "\n",
    "And finally create the kube-apiserver configuration file.\n",
    "\n",
    "Most of the options provided in these we have seen already throughout this course such as the various\n",
    "\n",
    "certificates and other options.\n",
    "\n",
    "We will now move to the kube-controller-manager configuration. Move the kube controller manager config\n",
    "\n",
    "to the right location. Then create the kube-controller-manager service file.\n",
    "\n",
    "Repeat the same for the kube-scheduler.\n",
    "\n",
    "Finally reload service daemon and enable services to start automatically during system startup, and\n",
    "\n",
    "start the services\n",
    "\n",
    "Verify the status of each service and ensure it is active. To perform a quick check to see if they are\n",
    "\n",
    "discovered by the api-server, run the kubectl get componentstatuses command using the admin kubeconfig\n",
    "\n",
    "file.\n",
    "\n",
    "Well that's it for this demo. In the next demo we look at configuring load balancer.\n",
    "\n",
    "\n",
    "## 178. Demo - Install Control Plane Load Balancer\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296244#overview\n",
    "\n",
    "In this demo we see how to configure a simple load balancer to route traffic to the kube-api servers.\n",
    "\n",
    "We will be using HA proxy. So we will install HA proxy application.\n",
    "\n",
    "Once installed\n",
    "\n",
    "create an HA proxy configuration file at /etc/haproxy/haproxy.cfg.\n",
    "\n",
    "Then, start the service. Verify its in an active state.\n",
    "\n",
    "Once done, confirm that you can reach the API server using curl.\n",
    "\n",
    "You should see the version as the output. Going forward\n",
    "\n",
    "we can use the load balancer IP address as the kube-api server.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 179. Demo - Bootstrap Worker Node\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296246#overview\n",
    "\n",
    "So we are done with the master nodes and load balancer.\n",
    "\n",
    "Now we have 2 worker nodes.\n",
    "\n",
    "We can easily configure both of them the same way and get them up and running.\n",
    "\n",
    "But we're going to take two separate approaches in configuring them. On the first worker node\n",
    "\n",
    "we will first generate certificates for our-self just like how we did for the other components in the\n",
    "\n",
    "cluster.\n",
    "\n",
    "Then get it signed by the CA and copied over to the worker node and configure the Kubelet service\n",
    "\n",
    "to use that certificate. Every time the certificate expires\n",
    "\n",
    "we renew it by ourself following the same process.\n",
    "\n",
    "Now when you have a cluster with thousands of nodes that can be a tedious task.\n",
    "\n",
    "We want the nodes to be able to manage the certificate by themselves.\n",
    "\n",
    "So for the second worker node we will follow a tier less bootstrap approach where we will configure\n",
    "\n",
    "the node so it can create certificates by itself. And get them signed by the CA by itself and start\n",
    "\n",
    "using them by itself.\n",
    "\n",
    "And when the certificate expires it can renew the certificates by itself.\n",
    "\n",
    "And finally we configure kube-proxy on both the nodes which has done the usual same way. We now look at\n",
    "\n",
    "bootstrapping the worker nodes. As discussed we will look at two approaches.\n",
    "\n",
    "The first is where we create and configure the TLS certificates ourselves.\n",
    "\n",
    "The second is where we perform a TLS bootstrap on the workers where the certificates are created\n",
    "\n",
    "and managed by the Kubelet itself.\n",
    "\n",
    "In this demo.\n",
    "\n",
    "We look at the first approach. We start by generating the required certificates for the Kubelet.\n",
    "\n",
    "So we will do these tasks on the master note.\n",
    "\n",
    "For this we first create the Open SSL config file with the worker DNS and IP in it and then create a\n",
    "\n",
    "key and certificate signing request.\n",
    "\n",
    "We then signed the certificate using the CA key pairs.\n",
    "\n",
    "The next step is to create the kubeconfig files.\n",
    "\n",
    "We will be pointing the Kubelet to the load balancer server.\n",
    "\n",
    "So we first set the IP of the load balancer server then generate the kubeconfig file\n",
    "\n",
    "Once done we copy the certificate and kubeconfig files to the worker nodes\n",
    "\n",
    "The next set of tasks are to download and install the Kubelet binaries and configure the Kubelet services.\n",
    "\n",
    "These will be done on the worker notes so we start by downloading the binaries first.\n",
    "\n",
    "Once done we create the required folder structures.\n",
    "\n",
    "We then make the binaries executable and copy the binaries to the bin folder. We then move the certificate\n",
    "\n",
    "files and kubeconfig files to the var lib Kubernetes directory\n",
    "\n",
    "and finally configured the service. We first create a Kubelet config file where we specify different\n",
    "\n",
    "options required for for the Kubelet such as the cluster domain cluster DNS server etc. and we then\n",
    "\n",
    "create the kubelet service definition file\n",
    "\n",
    "similarly configure the Kubelet proxy service\n",
    "\n",
    "once then reload enable and start the service\n",
    "\n",
    "check the status of the service make sure it's active ignore the errors related to network for now as\n",
    "\n",
    "we have not configured networking yet. Run the kubecontrol get nodes command and ensure the worker is present\n",
    "\n",
    "again ignore the not ready state that is because networking is not configured yet.\n",
    "\n",
    "\n",
    "## 180. TLS Bootstrap worker node\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296250#overview\n",
    "\n",
    "Hello and welcome to this lecture. In this lecture\n",
    "\n",
    "we will get an overview of how the TLS bootstrapping process works in Kubernetes.\n",
    "\n",
    "So here's where we are now.\n",
    "\n",
    "We've configured two master nodes a load balancer and one worker node.\n",
    "\n",
    "We will now see how we can bootstrap the second worker node using the TLS bootstrap approach. Let's\n",
    "\n",
    "try to simplify this by only looking at a master\n",
    "\n",
    "and would-be worker node.\n",
    "\n",
    "There are two types of certificates configured on the worker nodes a server certificate and a client\n",
    "\n",
    "certificate.\n",
    "\n",
    "In the previous method while configuring the kubelet for worker-1, we specified the path to the server\n",
    "\n",
    "certificates for kubelet on worker-1 in its service configuration file like this.\n",
    "\n",
    "This is used by clients to connect to the kubelet.\n",
    "\n",
    "So who is a client and why would they connect to the kubelet?\n",
    "\n",
    "As of now the only client that connects to the kubelet is the kube-apiserver itself to monitor the\n",
    "\n",
    "state of the node, as well as to pull logs of PODs running on the worker node.\n",
    "\n",
    "when you run the kubectl logs command, or when you try to execute a command on a POD on the worker\n",
    "\n",
    "node using the kubectl exec command. In case of worker-2 we don’t have those generated, and we don’t\n",
    "\n",
    "want to do that by ourself.\n",
    "\n",
    "We also configured the kubeconfig file, which has the client certificates used by kubelet to\n",
    "\n",
    "connect to the kube-api server.\n",
    "\n",
    "Our goal with TLS bootstrapping is to automate the certificate management so the kubelet\n",
    "\n",
    "can take care of it by itself. All certificate related operations are carried out using these certificates\n",
    "\n",
    "API which we have discussed about earlier in this course. For using the Certificates API the kubelet\n",
    "\n",
    "needs to be able to authenticate into the kube-apiserver with the right set of permissions.\n",
    "\n",
    "So the first set of tasks that we are going to discuss here is to create the necessary set of permissions\n",
    "\n",
    "on the master node to allow the worker nodes to make these requests. A special type of authentication\n",
    "\n",
    "token called “bootstrap token” can be created for this purpose. Associate the bootstrap token to a group\n",
    "\n",
    "called system:bootstrappers.\n",
    "\n",
    "We then configure the kubelet to use this token to authenticate into the API server. We can use the\n",
    "\n",
    "same token for all the worker nodes or create a separate one for each node. Once configured,\n",
    "\n",
    "What kind of permissions do these tokens have.\n",
    "\n",
    "Can they make any API calls on the API server?\n",
    "\n",
    "If so wouldn’t that be a security risk,\n",
    "\n",
    "since we plan to distribute this token to all new worker nodes? Well the token does not have any permission\n",
    "\n",
    "to start with.\n",
    "\n",
    "So you must assign a role to it, for it to have enough permissions to make certain API calls. A default\n",
    "\n",
    "cluster role exists for this purpose, known as the system:node-bootstrapper role.\n",
    "\n",
    "This gives just enough permissions for the kubelet to submit a Certificate Signing Request to the API\n",
    "\n",
    "server.\n",
    "\n",
    "Once this permission is assigned, the kubelet is able to generate a pair certificates and submit\n",
    "\n",
    "the certificate signing request to the kube-apiserver.\n",
    "\n",
    "At this point if you run the kubectl get csr command, you will see a new csr request come in for this\n",
    "\n",
    "node.\n",
    "\n",
    "Now you can chose to manually approve it post which the worker node will fetch the certificate and\n",
    "\n",
    "start using it.\n",
    "\n",
    "But if you have a cluster with 1000s of nodes it’s going to be a tedious task.\n",
    "\n",
    "So you can chose to allow these certificates to be automatically approved, by associating another role\n",
    "\n",
    "to the group called system:certificats:certificatesigningrequests:nodeclient. With this role assigned\n",
    "\n",
    "to the system:bootstrappers group, the csr gets approved automatically as soon as it is submitted and the\n",
    "\n",
    "node becomes part of the cluster. Once the node joins the cluster,\n",
    "\n",
    "It becomes part of this system node group and it no longer needs the bootstrap token going forward sometime\n",
    "\n",
    "in the future when the certificate expires.\n",
    "\n",
    "If you want the node to be able to renew certificate by itself then associate the cluster roll certificate\n",
    "\n",
    "certificatesigningsrequests selfnodeclient to the system:nodes group. Now that we have created the necessary tokens\n",
    "\n",
    "and groups and role associations in the master node.\n",
    "\n",
    "it is time to configure the kubelet. You don’t have to remember all these groups by heart,\n",
    "\n",
    "These are available in the kubernetes documentation page.\n",
    "\n",
    "But this just a high level overview of how TLS bootstrapping works,\n",
    "\n",
    "so when you walk through the documentation, you can easily follow. In the kubelet service configuration,\n",
    "\n",
    "we earlier had TLS certifications.\n",
    "\n",
    "We don't have that anymore.\n",
    "\n",
    "Instead we add a new flag called bootstrap-kubeconfig where we provide the path to a kubeconfig file\n",
    "\n",
    "that has the bootstrap token in it.\n",
    "\n",
    "The bootstrap kube-config file is like any other kube-config file, except instead of using certificates\n",
    "\n",
    "to authenticate to the API, we use the bootstrap token in the form token-id dot token-secret\n",
    "\n",
    "With this setup,\n",
    "\n",
    "the worker should be able to use the bootstrap token to get signed certificates from the master api\n",
    "\n",
    "server. To enable the kubelet to automatically renew or rotate certificates when they expire,\n",
    "\n",
    "You must set the rotate certificate flags to true. Now whatever we have discussed so far is applicable\n",
    "\n",
    "to the kubelet client certificates only. The client certificates that kubelet uses to connect to the API\n",
    "\n",
    "server to join the cluster. The server certificates\n",
    "\n",
    "as you can see are still created by us and configured in the kubelet service configuration file. To\n",
    "\n",
    "enable the kubelet to automatically request and rotate server certificates as well,\n",
    "\n",
    "Set the rotate server certificates flags to true.\n",
    "\n",
    "Now there is one difference between how the server and client certificates are handled. For the client\n",
    "\n",
    "certificates.\n",
    "\n",
    "as we saw the certificate signing requests are automatically approved.\n",
    "\n",
    "However, that is not the case for server certificates. Server certificates are not automatically approved\n",
    "\n",
    "for security reasons.\n",
    "\n",
    "You must manually approve them yourself using the kubectl approve command. Once the kubelet starts\n",
    "\n",
    "list the certificate signing requests and you will see two of them.\n",
    "\n",
    "The One with the name node and from the requestor bootstrap is automatically approved. That’s the bootstrap\n",
    "\n",
    "client certificate.\n",
    "\n",
    "The other in pending is the server certificate. To approve that run the kubectl certificate approve\n",
    "\n",
    "command.\n",
    "\n",
    "Well that's a high level overview of what we need to do for enabling TLS bootstrap for Kubelet in\n",
    "\n",
    "the upcoming demo.\n",
    "\n",
    "We will see this in action.\n",
    "\n",
    "\n",
    "\n",
    "## 181. Demo - TLS Bootstrap worker node\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296252#overview\n",
    "\n",
    "In this demo, we look at TLS bootstrapping a worker node. The worker-2 node in our case. To enable\n",
    "\n",
    "TLS bootstrapping feature\n",
    "\n",
    "You must meet two prerequisites.\n",
    "\n",
    "The first is to have the \"enable bootstrap token auth\" option set to true on the kube-api server.\n",
    "\n",
    "We can check this by running ps aux command and looking at the kube-api server process. We see that\n",
    "\n",
    "it is enabled in our case. The next is for the controller manager to have the cluster signing certificate\n",
    "\n",
    "and key.\n",
    "\n",
    "gain we use the ps command to list the controller-manager and we see its, it's configured correctly\n",
    "\n",
    "once then we proceed with a bootstrapping process. On the worker node\n",
    "\n",
    "download the required binaries for kubelet, kube-proxy and kubectl utility.\n",
    "\n",
    "then create the required directory structures and then move the binaries to the bin directory\n",
    "\n",
    "Finally move the CA certificate in place.\n",
    "\n",
    "Note that we do not have the kubelet certificate generated in this case. As discussed in the previous lecture,\n",
    "\n",
    "we must create bootstrap token to be used by the kubelet.\n",
    "\n",
    "So do this by creating a bootstrap token secret object.\n",
    "\n",
    "Then authorize the bearer of that token,\n",
    "\n",
    "the worker nodes, permission to create CSR.\n",
    "\n",
    "For this we create a cluster roll binding object.\n",
    "\n",
    "We can do this in two ways, either by create a YAML definition file, the declarative way or with a single\n",
    "\n",
    "command the imperative way. We will follow the imperative approach.\n",
    "\n",
    "Next Authorize the worker to approve the CSR by creating another cluster role binding.\n",
    "\n",
    "And finally authorize the worker to renew CSR by itself.\n",
    "\n",
    "We then configure the kubelet to bootstrap. Earlier for worker-1\n",
    "\n",
    "remember we created a kubeconfig file with the certificates we created?\n",
    "\n",
    "Well, we don't have certificates for worker-2. So we don't create a kubeconfig file.\n",
    "\n",
    "Instead we create a bootstrap kubeconfig file with the bootstrap token we created. Again you can do\n",
    "\n",
    "this with 4 individual commands, the commands that we saw earlier in this course, or you can just create\n",
    "\n",
    "the bootstrap kubeconfig file maually.\n",
    "\n",
    "It's the same thing.\n",
    "\n",
    "We then create the kubelet config file which has information about the environment.\n",
    "\n",
    "And finally we configure the kubelet service itself.\n",
    "\n",
    "We specify the bootstrap kubeconfig option instead of the usual of kubeconfig option.\n",
    "\n",
    "We then configure kube-proxy. kube-proxy is configured as usual.\n",
    "\n",
    "Once done, reload, enable and start the services. Verify the state of the kubelet service. Ensure it\n",
    "\n",
    "is active\n",
    "\n",
    "Let us now check the status of CSRs on the mater.\n",
    "\n",
    "The client certificates used by kubelet to access the api server gets approved automatically. However\n",
    "\n",
    "you can see the one for the kubelet-server is in a pending state. Run the kubectl certificate approve\n",
    "\n",
    "command to approve it\n",
    "\n",
    "Verify the state of the nodes by running the kubectl get nodes command.\n",
    "\n",
    "we have successfully joined the worker node to the cluster.\n",
    "\n",
    "\n",
    "\n",
    "## 182. Configure kubectl for Remote Access\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14299686#overview\n",
    "\n",
    "In this demo, we see how to create the Kubeconfig file that will be used for accessing our cluster remotely.\n",
    "\n",
    "We will use the load IP address and the admin user's credentials and certificates in the Kube\n",
    "\n",
    "config file\n",
    "\n",
    "Once created\n",
    "\n",
    "we verify that it is in the user's home directory under the .Kube folder\n",
    "\n",
    "run the Kubectrl get components statuses and the Kubectrl get nodes command to verify that we can\n",
    "\n",
    "access the cluster.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 183. Demo - Deploy POD Networking Solution - Weave\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14299704#overview\n",
    "\n",
    "Let is now configure networking in the cluster.\n",
    "\n",
    "First we check the status of the cluster\n",
    "\n",
    "We see that it has 2 node and that the worker nodes are not ready.\n",
    "\n",
    "Let's look at one of these nodes to find out why it is not ready.\n",
    "\n",
    "Run the Kubectrl describe node command and you will see the reason it says network plugin is not configured\n",
    "\n",
    "correctly.\n",
    "\n",
    "So let's provision and network.\n",
    "\n",
    "We decided to use weave as our networking solution before we can provision weave we must ensure the\n",
    "\n",
    "required prerequisites are met on the worker node.\n",
    "\n",
    "The weave plugin relies on a few others CNI plugins.\n",
    "\n",
    "So we must first provision the default network CNI plugins on the worker nodes.\n",
    "\n",
    "For this we download the CNI plugins to both the worker nodes\n",
    "\n",
    "and then extract them to the OPT CNI bin directory\n",
    "\n",
    "once done.\n",
    "\n",
    "It's very easy to deploy the weave plugins on Kubernetes simply apply the weave deployment definition file\n",
    "\n",
    "from any of the master nodes and it creates the required objects.\n",
    "\n",
    "The weave agents are deployed as daemon sets so an agent runs on each node monitor the status of the\n",
    "\n",
    "pods and wait for them to be provisioned.\n",
    "\n",
    "Once they're in the running state run the Kubectrl get nodes command and you will see that the workers\n",
    "\n",
    "are now ready.\n",
    "\n",
    "We're all set with networking pods in Kubernetes.\n",
    "\n",
    "\n",
    "\n",
    "## 184. Demo - Kube-api to Kubelet connectivity\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296254#overview\n",
    "\n",
    "We now have our cluster setup, worker nodes added and networking provisioned.\n",
    "\n",
    "Let's perform a few checks to see if everything is functioning correctly.\n",
    "\n",
    "We list the nodes and they look good.\n",
    "\n",
    "We list the pods\n",
    "\n",
    "and they look good.\n",
    "\n",
    "Let us try to list the logs of the networking pod.\n",
    "\n",
    "The weave part deploys two containers so you must specify the name of the container to view its logs.\n",
    "\n",
    "So let's try that. when I try that\n",
    "\n",
    "you see it says it's forbidden.\n",
    "\n",
    "Now why is that.\n",
    "\n",
    "What's happening when we do this.\n",
    "\n",
    "Like how is kube-api server hosted on the master nodes able to pull logs from a pod or container\n",
    "\n",
    "hosted on the worker nodes.\n",
    "\n",
    "Of course it must be through the kubelet.\n",
    "\n",
    "So the API server requires permissions on the kubelet to access\n",
    "\n",
    "its resources. And we haven't done anything so far to give the api-server those set of permissions.\n",
    "\n",
    "We do that by creating a cluster role and then binding that cluster to the api-server. So we first\n",
    "\n",
    "create a cluster role for kube-apiserver-to-kubelet connectivity with the resources nodes/proxy, stats,\n",
    "\n",
    "log, spec and metrics.\n",
    "\n",
    "Then create a cluster role binding to bind that role to the kube-api server.\n",
    "\n",
    "Once that is created check the logs again and you'll see the output.\n",
    "\n",
    "Well this is an interesting place to look at.\n",
    "\n",
    "if you run into issues while fetching logs or executing commands on pods while troubleshooting.\n",
    "\n",
    "\n",
    "## 186. Deploy core DNS\n",
    "\n",
    "https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296260#overview\n",
    "\n",
    "The final task is to deploy a DNS server solution to our cluster\n",
    "\n",
    "As with networking\n",
    "\n",
    "this is again very easy.\n",
    "\n",
    "Simply apply the coredns manifest file which will deploy a service account, cluster role, role\n",
    "\n",
    "bindings, configmap, the deployment that hosts coredns and the service object.\n",
    "\n",
    "Wait for the pods to be deployed.\n",
    "\n",
    "Once they are running, verify that they are working correctly, by deploying a pod.\n",
    "\n",
    "We will use the kubectl run command to deploy a busy-box image.\n",
    "\n",
    "Then from within the busybox image perform an NS lookup for kubernetes. It should resolve to the IP\n",
    "\n",
    "of the DNS server.\n",
    "\n",
    "Well that's it for this demo.\n",
    "\n",
    "We're not all set with our cluster in the upcoming demos.\n",
    "\n",
    "We will see how to validate and test our cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
